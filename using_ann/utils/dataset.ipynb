{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"dataset.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"99Ktn6LLQP7W","executionInfo":{"status":"ok","timestamp":1651223798060,"user_tz":-540,"elapsed":27059,"user":{"displayName":"정가영","userId":"05535763540856384228"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ba17eb7f-f7ac-4a54-a6d9-e306efc04079"},"source":["import pandas as pd\n","import torch\n","from torch.utils.data import Dataset\n","from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler, OneHotEncoder\n","import numpy as np\n","#from google.colab import drive\n","#drive.mount('/content/drive')\n","\n","class jobDataset(Dataset):\n","\tdef __init__(self, mode):\n","\t\tself.mode = mode\n","\n","\t\tself.job_companies=pd.read_csv('/content/drive/MyDrive/연습/채용공고추천/data/job_companies.csv')  ## (733, 3)\n","\t\tself.job_tags=pd.read_csv('/content/drive/MyDrive/연습/채용공고추천/data/job_tags.csv')  ## (3477, 2)\n","\t\tself.tags=pd.read_csv('/content/drive/MyDrive/연습/채용공고추천/data/tags.csv')  ## (887, 2)\n","\t\tself.user_tags=pd.read_csv('/content/drive/MyDrive/연습/채용공고추천/data/user_tags.csv')  ## (17194, 2)\n","\t\tself.train=pd.read_csv('/content/drive/MyDrive/연습/채용공고추천/data/train.csv')  ## (6000, 3)\n","\t\tself.test=pd.read_csv('/content/drive/MyDrive/연습/채용공고추천/data/test_job.csv')  ## (2435, 2)\n","\n","\t\tself.train=self.train.merge(self.job_companies[['jobID', 'companySize']], on='jobID')\n","\t\tself.test=self.test.merge(self.job_companies[['jobID', 'companySize']], on='jobID')\n","\n","\t\tself.train['companySize']=self.train['companySize'].apply(lambda x:self.midd(x) if type(x)==str else x)\n","\t\tself.test['companySize']=self.test['companySize'].apply(lambda x:self.midd(x) if type(x)==str else x)\n","  \n","\t\ttrain_mid = self.train['companySize'].median()\n","\t\ttest_mid = self.test['companySize'].median()\n","\t\tself.train['companySize']=self.train['companySize'].fillna(train_mid)\n","\t\tself.test['companySize']=self.test['companySize'].fillna(test_mid)\n","\n","\n","\t\tself.train['tag_match_rate']=self.tag_match(self.train)\n","\t\tself.test['tag_match_rate']=self.tag_match(self.test)\n","\n","\t\t'''\n","\t\tle = LabelEncoder()  \n","\t\tself.train['jobID'] = le.fit_transform(self.train['jobID'].values.reshape(-1, 1))\n","\t\tfor label in np.unique(self.test['jobID']):\n","\t\t\tif label not in le.classes_: le.classes_=np.append(le.classes_,label)\n","\t\tself.test['jobID']=le.transform(self.test['jobID'].values.reshape(-1, 1))\n","\t\t'''\n","\t\toe=OneHotEncoder(handle_unknown='ignore')\n","\t\toe_result = oe.fit_transform(self.train['jobID'].values.reshape(-1, 1)).toarray()\n","\t\tsub=pd.DataFrame(data=oe_result, columns=oe.get_feature_names(['jobID']))\n","\t\tself.train=pd.concat([self.train, sub], axis=1)\n","\n","\t\toe_result = oe.transform(self.test['jobID'].values.reshape(-1, 1)).toarray()\n","\t\tsub=pd.DataFrame(data=oe_result, columns=oe.get_feature_names(['jobID']))\n","\t\tself.test=pd.concat([self.test, sub], axis=1)\n","\t\t\n","\n","\t\tle2 = LabelEncoder()  \n","\t\tself.train['userID'] = le2.fit_transform(self.train['userID'].values.reshape(-1, 1))\n","\t\tself.test['userID']=le2.transform(self.test['userID'].values.reshape(-1, 1))\n","\n","\n","\t\tself.train['companySize']=self.train.companySize.apply(lambda x: np.log(x, where =(x!=0)))\n","\t\tself.train['tag_match_rate']=self.train.tag_match_rate.apply(lambda x: np.log(x) if x!=0 else x)\n","\n","\t\tself.test['companySize']=self.test.companySize.apply(lambda x: np.log(x, where =(x!=0)))\n","\t\tself.test['tag_match_rate']=self.test.tag_match_rate.apply(lambda x: np.log(x) if x!=0 else x)\n","  \n","\n","\t\tst_scaler1 = StandardScaler()\n","\t\tself.train['companySize']=st_scaler1.fit_transform(self.train['companySize'].values.reshape(-1,1))\n","\t\tself.test['companySize']=st_scaler1.transform(self.test['companySize'].values.reshape(-1,1))\n","\n","\t\tst_scaler2 = StandardScaler()\n","\t\tself.train['tag_match_rate']=st_scaler2.fit_transform(self.train['tag_match_rate'].values.reshape(-1,1))\n","\t\tself.test['tag_match_rate']=st_scaler2.transform(self.test['tag_match_rate'].values.reshape(-1,1))\n","\n","\t\tif self.mode=='Train':\n","\t\t\tself.label = self.train['applied']\n","\t\t\tself.data = self.train.drop('applied', axis=1)\n","\t\t\tself.label = torch.FloatTensor(self.label.values)\n","\t\telse: self.data=self.test\n","\t\tself.data=self.data.drop('jobID',axis=1)  #################  one hot endcoding 시에 추가\n","\t\tself.data.head(5)\n","\t\tself.data = torch.FloatTensor(self.data.values)\n","\n","\t\tprint(self.data.shape)\n","  \n","\n","\tdef __len__(self):\n","\t\treturn self.data.shape[0]\n","  \n","\tdef __getitem__(self, idx):\n","\t\tif self.mode==\"Train\": \n","\t\t\treturn self.data[idx], self.label[idx]\n","\t\telse: return self.data[idx]\n","\n","\n","\tdef midd(self, data):\n","\t\tif data=='1000 이상': return 1000\n","\t\tdata=data.split('-')\n","\t\treturn (int(data[0])+int(data[1]))//2\n","\n","\n","\tdef tag_match(self, data):\n","\t\ttag = []\n","\t\tuser=data['userID']\n","\t\tjob=data['jobID']\n","\t\tfor u, j in zip(user, job):\n","\t\t\t# user_tags에서 현재 user와 일치하는 userID의 tagID만 가져옵니다.user의 관심사 키워드를 가져옵니다.\n","\t\t\tuser_tag=self.user_tags[self.user_tags['userID']==u]['tagID'].values\n","\n","\t\t\t# job_tags에서 현재 user의 job과 일치하는 jobID의 tagID만 가져옵니다. job의 키워드를 가져옵니다.\n","\t\t\tjob_tag=self.job_tags[self.job_tags['jobID']==j]['tagID'].values\n","\n","\t\t\tjob_tag_total=len(job_tag) # job의 해당 키워드가 총 몇개인지\n","\t\t\tcnt=0\n","\t\t\tfor i in user_tag:\n","\t\t\t\t# user의 관심 키워드가 job의 키워드와 일치한다면 cnt를 1증가시켜 줍니다.\n","\t\t\t\tif i in job_tag: cnt+=1 \n","\t\t\n","\t\t\t# job의 전체 키워드중 몇개가 user의 관심사 키워드와 일치했는지 비율을 계산해줍니다.\n","\t\t\ttag.append(cnt/job_tag_total)\n","\t\treturn tag\n","jobDataset('Train')"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([6000, 3])\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"]},{"output_type":"execute_result","data":{"text/plain":["<__main__.jobDataset at 0x7f1e71731610>"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"esQhhKybMBwy","executionInfo":{"status":"ok","timestamp":1651222020747,"user_tz":-540,"elapsed":26669,"user":{"displayName":"정가영","userId":"05535763540856384228"}},"outputId":"7deb3810-4988-4aad-f216-45ee812a1154"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]}]}